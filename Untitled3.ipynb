{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled3.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1F_Zw6aPa6cCvSS_BXbx4gBLZC40DxhO3",
      "authorship_tag": "ABX9TyMfg0iWtGC9M+mSKjTZg3r8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LimHaksoo/Face-Mask-Detection/blob/master/Untitled3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YbJ8xw5KrtQY"
      },
      "source": [
        "import torch\r\n",
        "from torch.utils.data import DataLoader\r\n",
        "import torch.nn as nn\r\n",
        "import torchvision\r\n",
        "import torchvision.transforms as transforms\r\n",
        "import torchvision.datasets as datasets\r\n",
        "import os\r\n",
        "import torch.optim as optim\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import os\r\n",
        "from PIL import Image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nj_QFI1DsHsB"
      },
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\r\n",
        "\r\n",
        "torch.manual_seed(777)\r\n",
        "if device =='cuda':\r\n",
        "    torch.cuda.manual_seed_all(777)\r\n",
        "\r\n",
        "trans = transforms.Compose([transforms.Resize((224,224)),\r\n",
        "                            transforms.ToTensor(),\r\n",
        "                            transforms.Normalize((0.485,0.456,0.406),(0.229,0.224,0.225))])\r\n",
        "\r\n",
        "train_dataset = datasets.ImageFolder(\r\n",
        "    \"/content/drive/MyDrive/test/mask/train\",\r\n",
        "    transform=trans)\r\n",
        "train_loader = torch.utils.data.DataLoader(\r\n",
        "    train_dataset, batch_size=256, shuffle=True,\r\n",
        "    num_workers=0)\r\n",
        "test_dataset = datasets.ImageFolder(\r\n",
        "    \"/content/drive/MyDrive/test/mask/test\",\r\n",
        "    transform=trans)\r\n",
        "test_loader = torch.utils.data.DataLoader(\r\n",
        "    test_dataset, batch_size=256, shuffle=True,\r\n",
        "    num_workers=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hbbqP_3HsrWv"
      },
      "source": [
        "import torch.nn as nn\r\n",
        "\r\n",
        "model_urls = {\r\n",
        "    'resnet50': 'https://download.pytorch.org/models/resnet50-19c8e357.pth'\r\n",
        "}\r\n",
        "\r\n",
        "import torchvision.models.resnet as resnet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gb0zICJx4iTU"
      },
      "source": [
        "conv1x1=resnet.conv1x1\r\n",
        "Bottleneck = resnet.Bottleneck\r\n",
        "BasicBlock= resnet.BasicBlock"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uE8u3zHo4jgP"
      },
      "source": [
        "class ResNet(nn.Module):\r\n",
        "\r\n",
        "    def __init__(self, block, layers, num_classes=1000, zero_init_residual=False):\r\n",
        "        super(ResNet, self).__init__()\r\n",
        "        self.inplanes = 16\r\n",
        "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1,\r\n",
        "                               bias=False)\r\n",
        "        self.bn1 = nn.BatchNorm2d(16)\r\n",
        "        self.relu = nn.ReLU(inplace=True)\r\n",
        "        #self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\r\n",
        "        \r\n",
        "        self.layer1 = self._make_layer(block, 16, layers[0], stride=1)\r\n",
        "        self.layer2 = self._make_layer(block, 32, layers[1], stride=1)\r\n",
        "        self.layer3 = self._make_layer(block, 64, layers[2], stride=2)\r\n",
        "        self.layer4 = self._make_layer(block, 128, layers[3], stride=2)\r\n",
        "        \r\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\r\n",
        "        self.fc = nn.Linear(128 * block.expansion, 2)\r\n",
        "\r\n",
        "        for m in self.modules():\r\n",
        "            if isinstance(m, nn.Conv2d):\r\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\r\n",
        "            elif isinstance(m, nn.BatchNorm2d):\r\n",
        "                nn.init.constant_(m.weight, 1)\r\n",
        "                nn.init.constant_(m.bias, 0)\r\n",
        "\r\n",
        "        # Zero-initialize the last BN in each residual branch,\r\n",
        "        # so that the residual branch starts with zeros, and each residual block behaves like an identity.\r\n",
        "        # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677\r\n",
        "        if zero_init_residual:\r\n",
        "            for m in self.modules():\r\n",
        "                if isinstance(m, Bottleneck):\r\n",
        "                    nn.init.constant_(m.bn3.weight, 0)\r\n",
        "                elif isinstance(m, BasicBlock):\r\n",
        "                    nn.init.constant_(m.bn2.weight, 0)\r\n",
        "\r\n",
        "    def _make_layer(self, block, planes, blocks, stride=1):\r\n",
        "        downsample = None\r\n",
        "        if stride != 1 or self.inplanes != planes * block.expansion:\r\n",
        "            downsample = nn.Sequential(\r\n",
        "                conv1x1(self.inplanes, planes * block.expansion, stride),\r\n",
        "                nn.BatchNorm2d(planes * block.expansion),\r\n",
        "            )\r\n",
        "\r\n",
        "        layers = []\r\n",
        "        layers.append(block(self.inplanes, planes, stride, downsample))\r\n",
        "        self.inplanes = planes * block.expansion\r\n",
        "        for _ in range(1, blocks):\r\n",
        "            layers.append(block(self.inplanes, planes))\r\n",
        "\r\n",
        "        return nn.Sequential(*layers)\r\n",
        "\r\n",
        "    def forward(self, x):\r\n",
        "        x = self.conv1(x)\r\n",
        "        #x.shape =[1, 16, 32,32]\r\n",
        "        x = self.bn1(x)\r\n",
        "        x = self.relu(x)\r\n",
        "        #x = self.maxpool(x)\r\n",
        "\r\n",
        "        x = self.layer1(x)\r\n",
        "        #x.shape =[1, 128, 32,32]\r\n",
        "        x = self.layer2(x)\r\n",
        "        #x.shape =[1, 256, 32,32]\r\n",
        "        x = self.layer3(x)\r\n",
        "        #x.shape =[1, 512, 16,16]\r\n",
        "        x = self.layer4(x)\r\n",
        "        #x.shape =[1, 1024, 8,8]\r\n",
        "        \r\n",
        "        x = self.avgpool(x)\r\n",
        "        x = x.view(x.size(0), -1)\r\n",
        "        x = self.fc(x)\r\n",
        "\r\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3z7F7eKL4mtH"
      },
      "source": [
        "resnet50 = ResNet(resnet.Bottleneck, [3, 4, 6, 3], 2, True).to(device) \r\n",
        "#1(conv1) + 9(layer1) + 12(layer2) + 18(layer3) + 9(layer4) +1(fc)= ResNet50"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AdtFVVtm4rpo"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss().to(device)\r\n",
        "optimizer = torch.optim.SGD(resnet50.parameters(), lr = 0.1, momentum = 0.9, weight_decay=5e-4)\r\n",
        "lr_sche = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VYQ1WZSlbFxB"
      },
      "source": [
        "train_loader.size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qxNKNPBN4vOY"
      },
      "source": [
        "print(len(train_loader))\r\n",
        "epochs = 1\r\n",
        "\r\n",
        "for epoch in range(epochs):  # loop over the dataset multiple times\r\n",
        "\r\n",
        "    for i, data in enumerate(train_loader, 0):\r\n",
        "        # get the inputs\r\n",
        "        inputs, labels = data\r\n",
        "        inputs = inputs.to(device)\r\n",
        "        labels = labels.to(device)\r\n",
        "\r\n",
        "        # zero the parameter gradients\r\n",
        "        optimizer.zero_grad()\r\n",
        "\r\n",
        "        # forward + backward + optimize\r\n",
        "        outputs = resnet50(inputs)\r\n",
        "        loss = criterion(outputs, labels)\r\n",
        "        loss.backward()\r\n",
        "        optimizer.step()\r\n",
        "\r\n",
        "        # print statistics\r\n",
        "        running_loss += loss.item()\r\n",
        "        if i % 30 == 29:    # print every 30 mini-batches\r\n",
        "            print('[%d, %5d] loss: %.3f' %\r\n",
        "                  (epoch + 1, i + 1, running_loss / 30))\r\n",
        "            running_loss = 0.0\r\n",
        "    \r\n",
        "print('Finished Training')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g4F335B25SrB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}