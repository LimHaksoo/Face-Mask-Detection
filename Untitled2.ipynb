{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled2.ipynb",
      "private_outputs": true,
      "provenance": [],
      "mount_file_id": "1Ki7jcMuDDqHJV7hkvn3rorhw53iUsgDC",
      "authorship_tag": "ABX9TyMeMZHlG/IIS96vMWFA+HMh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LimHaksoo/Face-Mask-Detection/blob/master/Untitled2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S1-MBJGKi8w4"
      },
      "source": [
        "!pip install tensorflow==2.1.0\r\n",
        "!pip install keras==2.3.1\r\n",
        "!pip install gdown"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W0l3ZfKPltpn"
      },
      "source": [
        "from tensorflow.compat.v1 import ConfigProto\r\n",
        "from tensorflow.compat.v1 import InteractiveSession\r\n",
        "\r\n",
        "config = ConfigProto()\r\n",
        "config.gpu_options.per_process_gpu_memory_fraction = 0.5\r\n",
        "config.gpu_options.allow_growth = True\r\n",
        "session = InteractiveSession(config=config)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GgIvOF33nYTt"
      },
      "source": [
        "import tensorflow\r\n",
        "from tensorflow.keras.layers import Input, Lambda, Dense, Flatten\r\n",
        "from tensorflow.keras.models import Model\r\n",
        "from tensorflow.keras.applications.inception_v3 import preprocess_input\r\n",
        "from tensorflow.keras.preprocessing import image\r\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator,load_img\r\n",
        "from tensorflow.keras.models import Sequential\r\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\r\n",
        "import numpy as np\r\n",
        "import os\r\n",
        "from glob import glob\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import tensorflow\r\n",
        "import keras\r\n",
        "print(tensorflow.__version__)\r\n",
        "print(keras.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HdRIlJYuKrSZ"
      },
      "source": [
        "# re-size all the images to this\r\n",
        "IMAGE_SIZE = [224, 224]\r\n",
        "\r\n",
        "train_path = \"/content/drive/MyDrive/test/mask/train\"\r\n",
        "valid_path  = \"/content/drive/MyDrive/test/mask/test\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HteQLplYK0HM"
      },
      "source": [
        "resnet152V2 = tensorflow.keras.applications.ResNet152V2(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BwIogieqK3ib"
      },
      "source": [
        "for layer in resnet152V2.layers:\r\n",
        "    layer.trainable = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9F0YEGciK-01"
      },
      "source": [
        "x = Flatten()(resnet152V2.output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ry3k5C72LFqT"
      },
      "source": [
        "folders = glob(\"/content/drive/MyDrive/test/mask/train/*\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "St72CrpxLHUO"
      },
      "source": [
        "prediction = Dense(len(folders), activation='softmax')(x)\r\n",
        "\r\n",
        "# create a model object\r\n",
        "model = Model(inputs=resnet152V2.input, outputs=prediction)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sbHdOMLbLru6"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u9XCmhS2LtvZ"
      },
      "source": [
        "# tell the model what cost and optimization method to use\r\n",
        "model.compile(\r\n",
        "  loss='categorical_crossentropy',\r\n",
        "  optimizer='adam',\r\n",
        "  metrics=['accuracy']\r\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cdtT3jnfLx0f"
      },
      "source": [
        "# Use the Image Data Generator to import the images from the dataset\r\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\r\n",
        "\r\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255,\r\n",
        "                                   shear_range = 0.2,\r\n",
        "                                   zoom_range = 0.2,\r\n",
        "                                   horizontal_flip = True)\r\n",
        "\r\n",
        "test_datagen = ImageDataGenerator(rescale = 1./255)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0HjKCPpLzYS"
      },
      "source": [
        "# Make sure you provide the same target size as initialied for the image size\r\n",
        "training_set = train_datagen.flow_from_directory(train_path,\r\n",
        "                                                 target_size = (224, 224),\r\n",
        "                                                 batch_size = 32,\r\n",
        "                                                 class_mode = 'categorical')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VcHMPi27L1fM"
      },
      "source": [
        "test_set = test_datagen.flow_from_directory(valid_path,\r\n",
        "                                            target_size = (224, 224),\r\n",
        "                                            batch_size = 32,\r\n",
        "                                            class_mode = 'categorical')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iNyaSbxGL4QA"
      },
      "source": [
        "# drive to save model\r\n",
        "\r\n",
        "os.makedirs('model', exist_ok=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uIapzOVLL55s"
      },
      "source": [
        "# save best model using vall accuracy\r\n",
        "model_path = '/content/model/resnet152v2.h5'\r\n",
        "checkpoint = ModelCheckpoint(model_path, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\r\n",
        "callbacks_list = [checkpoint]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UTgeGdM9L_de"
      },
      "source": [
        "# fit the model\r\n",
        "\r\n",
        "r = model.fit(\r\n",
        "  training_set,\r\n",
        "  validation_data=test_set,\r\n",
        "  epochs=10,\r\n",
        "  steps_per_epoch=len(training_set),\r\n",
        "  validation_steps=len(test_set),\r\n",
        "  callbacks=callbacks_list\r\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-C_YtkdzMHHO"
      },
      "source": [
        "import matplotlib.pyplot as plt\r\n",
        "# plot the loss\r\n",
        "plt.plot(r.history['loss'], label='train loss')\r\n",
        "plt.plot(r.history['val_loss'], label='val loss')\r\n",
        "plt.legend()\r\n",
        "plt.show()\r\n",
        "plt.savefig('LossVal_loss')\r\n",
        "\r\n",
        "# plot the accuracy\r\n",
        "plt.plot(r.history['accuracy'], label='train acc')\r\n",
        "plt.plot(r.history['val_accuracy'], label='val acc')\r\n",
        "plt.legend()\r\n",
        "plt.show()\r\n",
        "plt.savefig('AccVal_acc')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Y5eq7PPMI0X"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}